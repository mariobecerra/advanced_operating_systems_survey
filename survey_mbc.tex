\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage[pass]{geometry}
\usepackage[backend=bibtex]{biblatex}

\addbibresource{bibliography.bib} %Imports bibliography file

\begin{document}

\newgeometry{bottom=2.5cm, left=2.1cm,right=2.1cm,top=2.5cm}

\title{Survey name (something about improving Apache Spark)}

\author{Mario~Becerra Contreras}

\date{Fall 2017}


\maketitle

\begin{abstract}

We got a pretty nice abstract regarding the subject that is being studied and analyzed. This is a superb abstract, like, really really good. It's like the best abstract ever, for real. This is the best abstract you'll see in quite a long time.

\end{abstract}

\section{Introduction}

Very cool intro.


\section{Overview of Apache Spark}

Apache Spark \cite{zaharia_spark:_2010} is an open-source cluster computing framework that started in 2009 at the University of California, Berkeley \cite{zaharia_apache_2016}. The project aimed at creating a unified engine for distributed data processing by using a model similar to MapReduce but with data-sharing capabilities. This data-sharing was implemented with an abstraction called Resilient Distributed Datasets (or RDDs) \cite{zaharia_resilient_2012}. The idea was that in traditional MapReduce jobs, iterative jobs as the ones that surge naturally in machine learning, graph algorithms and interactive data mining suffer from a high overhead because of the continuous reading of the same data from disk. This could be improved by leveraging distributed memory. Back in the day, the only way to reuse data between computations was to write in a file system, which also incurred in a lot of overhead. 

Today, Spark is commonly used with distributed file systems such as Hadoop Distributed File System (HDFS) \cite{Shvachko2010}. It has grown and become one of the most active open-source projects, having over 1000 contributors and used in more than 1000 companies \cite{zaharia_apache_2016}. It is used widely in industry and has more than 350 third-party packages \cite{SparkPackages}, and four main high-level libraries that facilitate the use of Spark: SparkSQL for relational queries \cite{armbrust2015spark}, Spark Streaming for discretized streams \cite{zaharia2013discretized}, GraphX for graph computations \cite{gonzalez2014graphx}, and MLlib for machine learning \cite{Meng2016}. These four libraries can be easily combined in applications.

An RDD is a fault-tolerant representation of a read-only collection of partitioned objects across many machines. RDDs can be created through two operations: data from a file system or from other RDDs. These operations are called transformations, and examples include \textit{map}, \textit{filter} and \textit{join}. These operations are evaluated lazily, this way an efficient plan to compute them can be executed. The evaluated is executed until an \textit{action} (like \textit{count}, \textit{collect} or \textit{save} operations) is called. RDDs are reliable because they can be efficiently rebuilt in case a partition is lost. They do this by keeping a log of the graph of transformations that were used to build an RDD (this is called the \textit{lineage} of the RDD). Recovery is faster than rerunning the program because a failed has several partitions which can be rebuilt on other nodes in parallel.

There are two types of dependencies in RDDs: narrow and wide. In wide narrow dependencies, each partition of the parent RDD is used by at most one partition of the child RDD; whilst in wide dependencies multiple partitions may depend on the same partition of the parent RDD. Wide dependencies are communication intensive because they involve data shuffle across the network and thus may be a performance bottleneck.

By default, RDDs are recomputed every time an action is performed, but users have the option to tell Spark to keep an RDD in memory. If the RDD doesn't fit in memory, it is spilled to disk. This option is what can make Spark several orders of magnitude faster than plain MapReduce jobs on Hadoop in iterative problems. Since the RDDs can be kept in memory, the reused dataset isn't loaded in every iteration. RDDs can express several cluster programming models in an efficient way; models such as MapReduce, SQL, Interactive MapReduce and Batched Stream Processing \cite{zaharia_resilient_2012}.




\section{Survey}

Even though Spark is a powerful computing framework, it is not perfect and has its caveats. There's been a handful of efforts to improve different areas of opportunity. Some are general improvements, whilst other are particularities that are suited for some tasks.

\subsection{Improvement based on communication}

As mentioned before, there's a performance bottleneck in the shuffling phase of wide dependencies. It is common to compress files before sending them in the network to alleviate this, but this is too dependent on the structure of the input data. \citeauthor{davidson2013optimizing} \cite{davidson2013optimizing} propose some alternatives to solve the problems that stress the OS during the shuffle phase. Since the number of shuffle files may be in the order of the millions in a usual Spark work, the number of random writes is quite big. The main proposed solution to this problem is to create larger shuffle files. The results show that the I/O wait time is lower with this modification, but disk throughput is sustained, meaning that much less random I/O is done by creating fewer shuffle files. They suggest as future work to do an in-memory shuffle when it is possible to fit the data in the cluster's collective memory.

This issue was addressed some time later by the Spark group themselves. \citeauthor{Armbrust2015} \cite{Armbrust2015} recognize the problem of shuffling operations on many nodes, along with some other memory and usability issues. The former affair was resolved by changing the original NIO-based network module with a new implementation based on Netty. The latter problems were specifically that memory management needed to be improved, that performance debugging was hard to do, and that there was some confusion about Spark's API.

The memory management issue was taken care of adding more caps to take care of compressed data that could scale from a few hundreds of MBs to a couple of GBs. As for the debugging, new metrics were added to the monitoring UI; allowing users to see things such as time taken to schedule, run and receive results from tasks. They also added new data visualization tools to monitor the jobs. The confusion about the API was addressed by developing a more declarative API, one that is based in data frames, such as the ones in Python and R. With this new API, the standard data frame interface is compiled using the optimizer in SparkSQL \cite{armbrust2015spark}. These data frames are also now being used as input and output between Spark's high level libraries. These changes were introduced in Spark's version 1.2.0.

One early work was to adapt RDMA (Remote Direct Memory Access) to Spark in an InfiniBand Architecture \cite{Lu2014}. The InfiniBand Architecture is ``a new industry-standard architecture for server I/O and inter-server communication'' \cite{pfister2001introduction}. The authors claim that Spark can't fully use InfiniBand's capabilities to obtain optimal performance, so they adapt RDMA to be a part of the communication infrastructure by overriding Spark's native features so RDMA calls would be used instead of the Java Socket interface. Their adaptation achieved an 83\% performance improvement in the test tasks that they used and conclude that with their RDMA-base design Spark applications could be improved.

This same group continued with this study \cite{Lu2016}: in \citeyear{Lu2016} they tested an advanced RDMA-based design in the changed Apache architecture that came with version 1.2.0 \cite{Armbrust2015}. They particularly check for improvements based on RDMA in the new shuffle architecture based in Netty instead of NIO. They implement an advanced design in three clusters with the most recent InfiniBand technologies and test several workloads on RDD Benchmarks, graph processing and SQL queries on top of Spark scaling up to 1536 cores. The results show that they achieve up to 79\% improvement in RDD performance, 46\% for graph workloads and 32\% for SQL queries. 

Even though Spark is most commonly used in large data centres, it can also be use in an HPC context, with supercomputers, such as Cray supercomputers. \citeauthor{Chaimov2016} study the performance of Spark in two Cray XC systems in a large supercomputing centre \cite{Chaimov2016}. They first test the performance of a single workstation with SSDs with a single node of a Cray XC and found that the Cray node was slower. They attributed this to the latency involved in opening files (in \texttt{fopen}). To calibrate the performance in the Cray they propose using a local file system in a Lustre file or main memory and to use pooling when opening files so that metadata is cached.
%They argue that in supercomputer settings, disk I/O is optimized for bandwidth and network is optimized for latency, unlike in data centres where disk I/O is primarily optimized for latency and network is optimized for bandwidth.

\subsection{Improvement based on file system, OS and JVM parameters}

Another work \cite{Islam2015} focused on studying the impacts of two file systems (Tachyon and Triple-H) on Spark applications. In particular, they identified critical parameters on the performance of the applications that run on top of these file systems, such as BlockSize, concurrent containers and concurrent tasks. They also propose selective caching into high performance memory layers (such as RAMDisks or SSDs). This selective caching refers to caching the data that is the output of an iteration coming from a map or reduce task. One more optimization comes from improving the cache eviction algorithm after each algorithm iteration. They see that CPU-bound workloads don't show as much benefit as I/O intensive ones, and that iterative applications gain performance over the Triple-H file system.

\citeauthor{Wang2016} \cite{Wang2016} study the behaviour of Linux virtual memory to find out the effect of kernel parameters. They test this with Spark workloads that are especially sensitive to memory parameter tuning. They test the effect of transparent huge page but find none. They find that enabling Non-uniform memory access (NUMA) yields better results for some workloads, though not all. The conclusion of this work is that better results can be achieved by tuning certain parameters, although this study was small and not so generalizable.

Since Spark runs on top of Java Virtual Machines (JVMs), another way to improve performance is to tune JVM parameters. \citeauthor{Chiba2016} use different JVM and OS parameters to try to take full advantage of computing resources \cite{Chiba2016}. They argue that Spark creates many objects in heaps, so garbage collection (GC) pause time is a parameter that may cause execution time to be too long. They propose a series of optimizations (such as reducing the nursery space in the heap, changing the number of JVMs in a single node and applying NUMA affinity) and then test them in the TPC-H query benchmark,  which is ``a decision support benchmark [that] consists of a suite of business oriented ad-hoc queries and concurrent data modifications'' \cite{TPC_H_benchmark}. They find that these optimizations performed up to 5 time faster and ran 30\% to 40\% faster on average.
% These guys cite some other papers that do similar work as theirs. Check them out. They also mention some future work on other Spark workloads. See if they continued.

\subsection{GPU-based improvement}

Some different work was done in \cite{Li2015}, where the main contribution was related to GPU computing. They propose ``the marriage of GPUs to CPU-based cluster computing framework''. To do so, they implement HeteroSpark, a framework that augments the usual Spark framework by using GPUs in Spark worker nodes. The function calls from Spark are read by HeteroSpark and directed to the GPU via Java's Remote Method Invocation (RMI). If a function call isn't implemented in the GPU, the developer may opt to use the original implementation or decide to implement it themselves. The results show that, not surprisingly, performance is much better with Heterospark. This is because of the GPU acceleration. What the authors remark is that this improvement was achieved without sacrificing neither programmability nor portability.

\subsection{Performance prediction based improvement}

\citeauthor{wang2015performance} \cite{wang2015performance} present a model that predicts execution time, memory consumption and I/O cost. The model first executes the Spark program on a cluster using a sample of the data, thus collecting information about execution time, memory consumption and I/O costs. They find that their predictions are accurate for execution time and memory consumption, but not so for I/O cost. They conclude that this approach can help better allocate resources in a cluster running Spark.

In a similar line of improvement, \citeauthor{Marco2017} \cite{Marco2017} develop a machine learning algorithm that predicts the memory requirement of any Spark application in order to use effective task co-location strategies. The machine learning model is trained for each specific task by taking a subset of the dataset that is going to be used and then fitting a set of linear and non-linear regressions. Their approach was tested with a range of Spark applications that cover different application domains and show an accurate system modeling model. Because of these accurate predictions, the memory resources are better utilized and thus the systems achieves performance improvements by effectively using the runtime task scheduler.


\section{Conclusion and future work}

Very nice conclusions.


\printbibliography
%\nocite{*}


\end{document}
