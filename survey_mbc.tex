\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage[pass]{geometry}
\usepackage[backend=bibtex]{biblatex}

\addbibresource{bibliography.bib} %Imports bibliography file

\begin{document}

\newgeometry{bottom=2.5cm, left=2.1cm,right=2.1cm,top=2.5cm}

\title{Survey name (something about improving Apache Spark)}

\author{Mario~Becerra Contreras}

\date{Fall 2017}


\maketitle

\begin{abstract}

We got a pretty nice abstract regarding the subject that is being studied and analyzed. This is a superb abstract, like, really really good. It's like the best abstract ever, for real. This is the best abstract you'll see in quite a long time.

\end{abstract}

\section{Introduction}

Very cool intro.


\section{Overview of Apache Spark}

Apache Spark \cite{zaharia_spark:_2010} is an open-source cluster computing framework that started in 2009 at the University of California, Berkeley \cite{zaharia_apache_2016}. The project aimed at creating a unified engine for distributed data processing by using a model similar to MapReduce but with data-sharing capabilities. This data-sharing was implemented with an abstraction called Resilient Distributed Datasets (or RDDs) \cite{zaharia_resilient_2012}. The idea was that in traditional MapReduce jobs, iterative jobs as the ones that surge naturally in machine learning, graph algorithms and interactive data mining suffer from a high overhead because of the continuous reading of the same data from disk. This could be improved by leveraging distributed memory. Back in the day, the only way to reuse data between computations was to write in a file system, which also incurred in a lot of overhead. 

Today, Spark is commonly used with distributed file systems such as Hadoop Distributed File System (HDFS). It has grown and become one of the most active open-source projects, having over 1000 contributors and used in more than 1000 companies \cite{zaharia_apache_2016}. It is used widely in industry and has more than 350 third-party packages \cite{SparkPackages}, and four main high-level libraries that facilitate the use of Spark: SparkSQL for relational queries \cite{Armbrust}, Spark Streaming for discretized streams \cite{Zahariab}, GraphX for graph computations \cite{Gonzalez}, and MLlib for machine learning \cite{Meng2016}. These four libraries can be easily combined in applications.

An RDD is a fault-tolerant representation of a read-only collection of partitioned objects across many machines. RDDs can be created through two operations: data from a file system or from other RDDs. These operations are called transformations, and examples include \textit{map}, \textit{filter} and \textit{join}. These operations are evaluated lazily, this way an efficient plan to compute them can be executed. The evaluated is executed until an \textit{action} (like \textit{count}, \textit{collect} or \textit{save} operations) is called. RDDs are reliable because they can be efficiently rebuilt in case a partition is lost. They do this by keeping a log of the graph of transformations that were used to build an RDD (this is called the \textit{lineage} of the RDD). Recovery is faster than rerunning the program because a failed has several partitions which can be rebuilt on other nodes in parallel.

By default, RDDs are recomputed every time an action is performed, but users have the option to tell Spark to keep an RDD in memory. If the RDD doesn't fit in memory, it is spilled to disk. This option is what can make Spark several orders of magnitude faster than plain MapReduce jobs on Hadoop in iterative problems. Since the RDDs can be kept in memory, the reused dataset isn't loaded in every iteration. RDDs can express several cluster programming models in an efficient way; models such as MapReduce, SQL, Interactive MapReduce and Batched Stream Processing \cite{zaharia_resilient_2012}.


\section{Survey}

Even though Spark is a powerful computing framework, it is not perfect and has its caveats. There's been a handful of efforts to improve different areas of opportunity. Some are general improvements, whilst other are particularities that are suited for some tasks.

One early work was to adapt RDMA (Remote Direct Memory Access) to Spark in an InfiniBand Architecture \cite{Lu2014}. The InfiniBand Architecture is ``a new industry-standard architecture for server I/O and inter-server communication'' \cite{pfister2001introduction}. The authors claim that Spark can't fully use InfiniBand's capabilities to obtain optimal performance, so they adapt RDMA to be a part of the communication infrastructure by overriding Spark's native features so RDMA calls would be used instead of the Java Socket interface. Their adaptation achieved an 83\% performance improvement in the test tasks that they used and conclude that with their RDMA-base design Spark applications could be improved.


\section{Conclusion and future work}

Very nice conclusions.


\printbibliography
\nocite{*}


\end{document}
